{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adiisharma0001/Aditya-s_Portfolio/blob/master/Time_Series_of_Price_Anomaly_Detection_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xe7CGEJec39"
      },
      "source": [
        "# The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjZ8lmyWd_fd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
        "\n",
        "print('Tensorflow version: ', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvbQ3E3WoMWy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('JNJ.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVkgd8wYovlO"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VINbOjOyo2Gk"
      },
      "outputs": [],
      "source": [
        "df = df[['Date', 'Close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AshjiZRTo9lW"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6PmeCNno9h1"
      },
      "outputs": [],
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHSu5dyspNc2"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8WbJsPbpSos"
      },
      "outputs": [],
      "source": [
        "df['Date'].min(), df['Date'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq1Gq6WSekWW"
      },
      "source": [
        "# Visualize the timeseries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBtqgeBseWze"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df['Date'], y=df['Close'], name='Close price'))\n",
        "fig.update_layout(showlegend=True, title='Johnson and Johnson Stock Price 1985-2020')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QcZ7keyi0zK"
      },
      "source": [
        "# Preprocessing\n",
        "**Train test split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqU4T659eWwD"
      },
      "outputs": [],
      "source": [
        "train, test = df.loc[df['Date'] <= '2013-09-03'], df.loc[df['Date'] > '2013-09-03']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8jtXJnNpnwf"
      },
      "outputs": [],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH-AnMaZpnuk"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbP-rVoBpntS"
      },
      "outputs": [],
      "source": [
        "train.shape,test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0PjWLZHi_vJ"
      },
      "source": [
        "**Standardize the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCgC2BjpeWuf"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(train[['Close']])\n",
        "\n",
        "train['Close'] = scaler.transform(train[['Close']])\n",
        "test['Close'] = scaler.transform(test[['Close']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5b5bXEfjQeg"
      },
      "source": [
        "# Create sequences\n",
        "Convert input data into 3-D array combining TIME_STEPS. The shape of the array should be [samples, TIME_STEPS, features], as required for LSTM network.\n",
        "\n",
        "We want our network to have memory of 30 days, so we set TIME_STEPS=30."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VXYMUIieWsr"
      },
      "outputs": [],
      "source": [
        "\n",
        "TIME_STEPS=30\n",
        "\n",
        "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X)-time_steps):\n",
        "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
        "        ys.append(y.iloc[i+time_steps])\n",
        "    \n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train, y_train = create_sequences(train[['Close']], train['Close'])\n",
        "X_test, y_test = create_sequences(test[['Close']], test['Close'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmL4WDOlqEXI"
      },
      "outputs": [],
      "source": [
        "print(f'Training shape: {X_train.shape}')\n",
        "print(f'Testing shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKm-3iMSje1s"
      },
      "source": [
        "# Build the Model\n",
        "We define the reconstruction LSTM Autoencoder architecture that expects input sequences with 30 time steps and one feature and outputs a sequence with 30 time steps and one feature.\n",
        "RepeatVector() repeats the inputs 30 times.\n",
        "Set return_sequences=True, so the output will still be a sequence.\n",
        "TimeDistributed(Dense(X_train.shape[2])) is added at the end to get the output, where X_train.shape[2] is the number of features in the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-PTBPG2eWqy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(RepeatVector(X_train.shape[1]))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzW5rRjYjsjR"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvlYVhCZeWpT"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
        "train_acc = 1 - train_loss\n",
        "print('Training accuracy:', train_acc)"
      ],
      "metadata": {
        "id": "yfYtGVmPFCTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYGHIjO0eWnm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx9pi-yreWlk"
      },
      "outputs": [],
      "source": [
        "# model.evaluate(X_test, y_test)\n",
        "\n",
        "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "test_acc = 1 - test_loss\n",
        "print('Training accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYDFHMTipdGO"
      },
      "source": [
        "# Determine Anomalies\n",
        "* Find MAE loss on the training data.\n",
        "* Make the max MAE loss value in the training data as the reconstruction error threshold.\n",
        "* If the reconstruction loss for a data point in the test set is greater than this reconstruction error threshold value then we will * label this data point as an anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiYp0yVSpcY1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "X_train_pred = model.predict(X_train, verbose=0)\n",
        "train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=1)\n",
        "\n",
        "sns.histplot(train_mae_loss, kde=True)\n",
        "plt.xlabel('Train MAE loss')\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(f'Reconstruction error threshold: {threshold}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeRCuw8LpcLX"
      },
      "outputs": [],
      "source": [
        "X_test_pred = model.predict(X_test, verbose=0)\n",
        "test_mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)\n",
        "sns.histplot(test_mae_loss, kde=True)\n",
        "plt.xlabel('Test MAE loss')\n",
        "plt.ylabel('Number of samples');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLQuQSoIp1Y_"
      },
      "outputs": [],
      "source": [
        "test_score_df = pd.DataFrame(test[TIME_STEPS:])\n",
        "test_score_df['loss'] = test_mae_loss\n",
        "test_score_df['threshold'] = threshold\n",
        "test_score_df['anomaly'] = test_score_df['loss'] > test_score_df['threshold']\n",
        "test_score_df['Close'] = test[TIME_STEPS:]['Close']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(test_score_df.index, test_score_df.loss, label='loss')\n",
        "plt.plot(test_score_df.index, test_score_df.threshold, label='threshold')\n",
        "plt.xticks(rotation=25)\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "wtc5HCagB96_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0Iy36LSp1V-"
      },
      "outputs": [],
      "source": [
        "anomalies = test_score_df.loc[test_score_df['anomaly'] == True]\n",
        "anomalies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCoD9y94r6-j"
      },
      "outputs": [],
      "source": [
        "anomalies.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmE9zOQOp_MV"
      },
      "source": [
        "# Visualize Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "# Plot the Close price and the anomalies as separate lines\n",
        "plt.plot(test_score_df['Date'], test_score_df['Close'], label='Close price')\n",
        "plt.plot(anomalies['Date'], anomalies['Close'], 'ro', label='Anomaly')\n",
        "\n",
        "# Add labels and a title\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Detected anomalies')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_kgiMhmsH67s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjHL5pS5p1UY"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=test_score_df['Date'],y=test_score_df['Close'], name=\"Close price\"))\n",
        "fig.add_trace(go.Scatter(x=anomalies['Date'], y=anomalies['Close'], name=\"Anomaly\"))\n",
        "fig.update_layout(showlegend=True, title='Detected anomalies')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFaulP_lp5MJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SwRC299p5JC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdb0UKGxp5HA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}